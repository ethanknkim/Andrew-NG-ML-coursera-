2019-07-09
ML: Study that gives computer the ability to learn w.o. being explicitly programmed.
"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E."

Example: playing checkers.

E = the experience of playing many games of checkers

T = the task of playing checkers.

P = the probability that the program will win the next game.

In general, any machine learning problem can be assigned to one of two broad classifications:

Supervised learning and Unsupervised learning.

Regression: Predict Continuous valued output

Classification: Discreted valued ouput

Training Set -> Learning Algorithm -> Hypothesis
x -> Hypothesis -> Estimated value
h = theta_0 + theta_1x

2019-07-10
Cost function = Squared Error Function: function of parameter theta_1(slope of hypothesis function)
Minimize 1/2m * sum of (h(x) - y)^2: Accuracy of hypothesis
h(x) = theta_0 + theta_1x

Gradient Descent(More Common Method)
Outline
start with theta_0,theta_1
keep change theta_0,theta_1 to minimize J(theta_0,theta_1) = 1/2m * sum of (h(x) - y)^2 to get to the minimum we want
Repeat Until Convergence {theta_j := theta_j - alpha * d/dtheta_j J(theta_0,theta_1)} (for j=0 and j=1)
alpha: learning rate
You simultaneously update theta_0 and theta_1
CORRECT WAY: compute temp0, temp1 and then assign temp0, temp1 to theta_0 and theta_1

2019-07-11
d/dtheta_j J(theta_0,theta_1) = d/dtheta_j 1/2m sum of (h(x)-y)^2
=d/dtheta_j*1/2m sum of (theta_0 + theta_1x - y)^2

Gradient Descent Algorithm
repeat until convergence {
theta_0 := theta_0 - alpha * 1/m sum of h(x)-y
theta_1 := theta_1 - alpha * 1/m sum of (h(x)-y)x
}

Batch Gradient Descent
"Batch": Each step of Gradient descent uses all the training examples

Matrix: Rectengular array of numbers
Dimension: # of rows x # of columns m-by-n matrix
A_ij ith row jth column
Scalar multiplication and addition: ez... learned in Univ.
Prediction = data matrix * parameters

2019-07-12
Multivariate Linear Regression
x_1 x_2 x_3.....(input variables)
y = (prediction variable)

n = number of features
x^(i) = ith training example
x^(i)_j = value of feature j in ith training example
X^(2) = 2nd training example
= [1416
3
2
40]
4-d vector it is.

Hypothesis :
h(x) = theta_0 + theta_1x_1 + theta_2x_2 +theta_3x_3 + theta_4x_4

For convenience, define x_0 = 1

Feature vector x = n+1 dimensional =[x0 x1 x2 ... xn]'
theta = n+1 dimensional = [theta_0 theta_1 ... theta_n]'

h(x) = theta' * x

New Gradient Descent Algorithm (n >=1)
Repeat {
theta_j := theta_j - alpha * 1/m * sum of (h(x^(i)) - y^(i))*x^(i)_j
} (simultaneously update thtea_j for j= 0, 1, 2, ...., n)

Feature Scaling
Idea: Make sure features are on a similar scale.

Get every feature into approx. -1=<x_i =<1 range.

mean normalization
replace x_i with x_i -  mu_i to make features have approx. 0 mean.
x1 <- x1-mu1/ s1
mu1 = average value of x1 in training set
s1 = range(max-min) or stdv.

Making Sure gradient descent is working correctly.
J(theta) should decrease after every iteration.

Example automatic convergence test: declare convergence if J(theta) decreases by less than 10^-3 in one iteration

Features and Polynomial Regression
Polynomial Regression

Normal Equation
Method to solve theta analytically
Intuition: you set derivative of J(theta) and make derivative 0
theta = (X'X)^-1X'y

Normal Equation noninvertibility
theta = (X'X)^-1*X'y
What if X'X is singular?
->Redundant features(linearly dependent)
->Too many features(e.g. m =< n)

2019-07-14
Classification
value y we want to predict is discret(0,1)
ex) email:spam/not spam, tumor: malignant/benign
y ={0,1}
0: "Negative Class"(benign tumor)
1: "Positive Class"(malignant tumor)
Hypothesis: = theta'*x
Threshold classifier output h(x) at 0.5:
h(x) >= 0.5, predict y=1
h(x) < 0.5, preidct y=0
Logistic Regression
: Want 0<=h(x)<=1
Hypothesis Representation
h(x) = g(theta'*x) =  1/(1+e^-(theta'*x))
g(z) = 1/(1+e^-z): logistic function(Sigmoid function)
Interpretation: h(x) = estimated probability that y=1 on input x
h(x) = p(y=1\x;theta) "probability that y=1, given x, parameterized by theta"

Decision Boundary
g(z) >= 0.5 when z >=0
therefore, h(x) >= 0.5 when g(theta'*x) >=0

ex: h(x) = g(theta0 + theta1*x1 + theta2*x2 )

Non-linear decision Boundary
